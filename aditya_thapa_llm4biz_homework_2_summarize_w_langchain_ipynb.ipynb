{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqXOJgJPBxoVND0CDcorEP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athapa785/LLM_4_Biz_Stanford/blob/main/aditya_thapa_llm4biz_homework_2_summarize_w_langchain_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHdqIWYd-o0D"
      },
      "outputs": [],
      "source": [
        "# Initialize key and client\n",
        "\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "open_ai_key = userdata.get('open_ai_key')\n",
        "\n",
        "client = OpenAI(api_key=open_ai_key)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grab \"Attention is all you need\"\n",
        "!wget https://arxiv.org/pdf/1706.03762"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bn__1JVEI6Ki",
        "outputId": "35bc5699-5602-4236-a73e-7087f81c7fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-08 05:22:39--  https://arxiv.org/pdf/1706.03762\n",
            "Resolving arxiv.org (arxiv.org)... 151.101.67.42, 151.101.195.42, 151.101.3.42, ...\n",
            "Connecting to arxiv.org (arxiv.org)|151.101.67.42|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2215244 (2.1M) [application/pdf]\n",
            "Saving to: ‘1706.03762.2’\n",
            "\n",
            "\r1706.03762.2          0%[                    ]       0  --.-KB/s               \r1706.03762.2        100%[===================>]   2.11M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-02-08 05:22:39 (163 MB/s) - ‘1706.03762.2’ saved [2215244/2215244]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community pypdf langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIBLzgMkJvV3",
        "outputId": "725cea25-ecc3-4ded-bc38-5caf3562ca7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.17)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.4)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.34)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.18 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.18)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.37)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.5)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.61.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.8.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain-community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "qvxFe8W3Jy9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\"1706.03762\")\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "CSDGO8yYJ4zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "rijmCHiAKNaN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown"
      ],
      "metadata": {
        "id": "tK1xsDyYKYJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0.1, model_name=\"gpt-4-turbo-preview\", api_key=open_ai_key)"
      ],
      "metadata": {
        "id": "w0JjjXcjKRjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_stuff = load_summarize_chain(llm, chain_type=\"stuff\")\n",
        "resp_stuff = chain_stuff.invoke(pages)"
      ],
      "metadata": {
        "id": "SzKa8QVOmJB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(resp_stuff[\"output_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "3C-Eoy-aKhbC",
        "outputId": "63d609a7-3127-4205-e600-ff40a4e60fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The paper \"Attention Is All You Need\" by Ashish Vaswani and colleagues at Google introduces the Transformer, a novel neural network architecture that relies entirely on an attention mechanism, eliminating the need for recurrent or convolutional layers in sequence transduction models. This architecture allows for significantly increased parallelization, reducing training times and achieving state-of-the-art results on machine translation tasks. The Transformer model achieved a BLEU score of 28.4 on the WMT 2014 English-to-German translation task and 41.8 on the English-to-French task, surpassing previous models and demonstrating superior quality and efficiency. The paper also explores the Transformer's application to English constituency parsing, showing its potential beyond translation tasks. The research highlights the benefits of self-attention mechanisms, including computational efficiency and the ability to capture long-range dependencies within sequences."
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain_map_reduce = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
        "\n",
        "resp_map_reduce = chain_map_reduce.invoke(pages)"
      ],
      "metadata": {
        "id": "fEC74rEHMNTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Noticed that map_reduce takes much longer."
      ],
      "metadata": {
        "id": "umlfn_DhlQ0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(resp_map_reduce[\"output_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "NbrcMCA-MS-C",
        "outputId": "10def003-45f5-44b5-ae5c-19549f8924a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The paper \"Attention Is All You Need\" by Ashish Vaswani et al. introduces the Transformer, a groundbreaking network architecture that exclusively uses attention mechanisms, eliminating the need for recurrent or convolutional neural networks. This model sets new benchmarks in machine translation, with impressive BLEU scores for English-to-German and English-to-French translations, and showcases superior training efficiency and parallelization capabilities. The Transformer, composed of an encoder and decoder featuring multi-head self-attention and feed-forward networks, excels in sequence transduction tasks, surpassing previous models in both speed and performance. It also shows promise in applications beyond machine translation, such as English constituency parsing. Additionally, the paper explores the Transformer's encoder self-attention mechanism's role in anaphora resolution, highlighting its technical and potential philosophical implications in understanding justice and language processing."
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try prompt templates."
      ],
      "metadata": {
        "id": "GHLyP0AnAaOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "n6T0EYwAKoiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prompt template\n",
        "prompt_template = \"\"\"Write a concise summary in a maximum of 3 bullets of the following text enclosed within three backticks:\n",
        "```{text}```\n",
        "Include heading as summary of the title of the text.\n",
        "CONCISE SUMMARY:\"\"\"\n",
        "prompt = PromptTemplate.from_template(prompt_template)"
      ],
      "metadata": {
        "id": "JM7CNBViLeKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LLM chain\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "TtTwirsXLoWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define StuffDocumentsChain\n",
        "stuff_chain = StuffDocumentsChain(llm_chain=llm_chain, document_variable_name=\"text\")\n",
        "\n",
        "resp = stuff_chain.invoke(pages)"
      ],
      "metadata": {
        "id": "Omnqy13FLvhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(resp[\"output_text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "ZbfZMYz4L57V",
        "outputId": "c00eb5ff-9e7f-48af-bce5-f6bd56b38461"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### \"Attention Is All You Need\" by Ashish Vaswani et al., Google Brain and Google Research\n\n- The paper introduces the Transformer, a novel neural network architecture based solely on attention mechanisms, eliminating the need for recurrence and convolutions in sequence transduction models. This architecture achieves state-of-the-art performance on machine translation tasks, outperforming existing models in both quality and training efficiency.\n- Experiments demonstrate the Transformer's effectiveness, achieving new state-of-the-art results on the WMT 2014 English-to-German and English-to-French translation tasks, with significant improvements over previous models. The architecture allows for more parallelization, reducing training time.\n- The Transformer also shows promising results in English constituency parsing, indicating its potential applicability beyond machine translation. The paper highlights the model's ability to learn long-range dependencies and its interpretability, with attention visualizations providing insights into the model's decision-making process."
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Translation tool"
      ],
      "metadata": {
        "id": "Jxq1V2bXSRD2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspiration: https://python.langchain.com/docs/tutorials/llm_chain/"
      ],
      "metadata": {
        "id": "beVCGgJJCpov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate"
      ],
      "metadata": {
        "id": "dRD4us-gh5RA"
      },
      "execution_count": 530,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_4o_conservative = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", api_key=open_ai_key)"
      ],
      "metadata": {
        "id": "JQMAYlC02bze"
      },
      "execution_count": 531,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_template = \"\"\"Translate the following from English to {language}.\n",
        "                  Do not be verbose. Try to do an almost word for word translation while preserving the meaning.\n",
        "                  If the script is not roman, it is absolutely essential for you to provide the roman transliteration in parenthesis after the translation in the native script.\n",
        "                  Output the name of the language in boldface.\n",
        "                  \"\"\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
        ")"
      ],
      "metadata": {
        "id": "D98XBJxuSIxy"
      },
      "execution_count": 532,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What are you doing?\"\n",
        "language = \"Nepali, Hindi, Mandarin, Korean, Japanese, Spanish, Italian, Greek, Norwegian, Swahili\""
      ],
      "metadata": {
        "id": "MlZLDsMoihRK"
      },
      "execution_count": 533,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = prompt_template.invoke({\"language\": language, \"text\": text})"
      ],
      "metadata": {
        "id": "AdcKvqU9h9AE"
      },
      "execution_count": 534,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm_4o_conservative.invoke(prompt)"
      ],
      "metadata": {
        "id": "mT_i0mOciPO3"
      },
      "execution_count": 535,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "eUPeI5TpiWB-",
        "outputId": "e86534b5-edce-424a-edf6-d6b7db404470"
      },
      "execution_count": 536,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Nepali:** के गर्दैछौ? (ke gardai chhau?)\n\n**Hindi:** तुम क्या कर रहे हो? (tum kya kar rahe ho?)\n\n**Mandarin:** 你在做什么？ (nǐ zài zuò shénme?)\n\n**Korean:** 뭐 하고 있어요? (mwo hago isseoyo?)\n\n**Japanese:** 何をしていますか？ (nani o shiteimasu ka?)\n\n**Spanish:** ¿Qué estás haciendo?\n\n**Italian:** Cosa stai facendo?\n\n**Greek:** Τι κάνεις; (Ti káneis?)\n\n**Norwegian:** Hva gjør du?\n\n**Swahili:** Unafanya nini?"
          },
          "metadata": {},
          "execution_count": 536
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pet name generator?"
      ],
      "metadata": {
        "id": "3YokPEKCkbua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspiration: https://www.youtube.com/watch?v=lG7Uxts9SXs"
      ],
      "metadata": {
        "id": "UCE69yhkDKYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "creative_llm = ChatOpenAI(temperature=1, model = \"gpt-4-turbo-preview\", openai_api_key=open_ai_key)"
      ],
      "metadata": {
        "id": "7clK7YCZi6Fm"
      },
      "execution_count": 537,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys_temp_animal = \"\"\"You are someone who comes up with creative names.\n",
        "          I will give you the animal type, personality, and color of my pet.\n",
        "          I want you to suggest me five cool names for my pet.\n",
        "          Use one word names only.\n",
        "          \"\"\"\n",
        "\n",
        "prompt_temp_animal = ChatPromptTemplate.from_messages(\n",
        "    [(\"system\", sys_temp_animal), (\"user\", \"{animal_info}\")]\n",
        ")"
      ],
      "metadata": {
        "id": "zj8YmfJ08rzE"
      },
      "execution_count": 538,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "animal_type = \"cat\"\n",
        "pet_color = \"brown\"\n",
        "personality = \"happy\"\n",
        "animal_info = f\"I have a {animal_type} with a {personality} personality, and it is {pet_color} in color.\""
      ],
      "metadata": {
        "id": "HAEcU7eI8jUI"
      },
      "execution_count": 539,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_animal = prompt_temp_animal.invoke({\"animal_info\": animal_info})"
      ],
      "metadata": {
        "id": "-AqxnNMN-JH9"
      },
      "execution_count": 540,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_animal = creative_llm.invoke(prompt_animal)"
      ],
      "metadata": {
        "id": "rdfKupjM_Kxu"
      },
      "execution_count": 541,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(response_animal.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "WIjq4JqS_P6A",
        "outputId": "52c99dcf-1ef6-4bce-cd43-3315bcb32389"
      },
      "execution_count": 542,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "1. Mocha\n2. Chipper\n3. Cider\n4. Maple\n5. Hazel"
          },
          "metadata": {},
          "execution_count": 542
        }
      ]
    }
  ]
}